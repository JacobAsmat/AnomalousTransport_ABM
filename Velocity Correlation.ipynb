{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import bootstrap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the input CSV file path\n",
    "input_csv_path = \"F:/OneDrive - The University of Manchester/SPIM Dros Jacob Tom/23_03/Embryo 6 (PVDRN)/23_03_23_E6_PVDRNz_Statistics/23_03_23_E6_PVDRNz_PosVel.csv\" \n",
    "w = 25 #moving average window\n",
    "c = 'tab:blue' #colour \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the base file name from the input CSV path (without extension)\n",
    "base_file_name = os.path.splitext(os.path.basename(input_csv_path))[0]\n",
    "\n",
    "# Find the last underscore and remove everything after it\n",
    "last_underscore_index = base_file_name.rfind('_')\n",
    "if last_underscore_index != -1:\n",
    "    base_file_name = base_file_name[:last_underscore_index]\n",
    "\n",
    "\n",
    "# Define the pearson CSV file path\n",
    "pearson_csv = f'F:/pearson/{base_file_name}_pearson2.csv'  # Replace with the path to your input CSV file\n",
    "\n",
    "\n",
    "# Extract the base file name from the input CSV path (without extension)\n",
    "base_file_name = os.path.splitext(os.path.basename(pearson_csv))[0]\n",
    "\n",
    "# Define user-defined titles\n",
    "column_title = \"Distance-based\"\n",
    "row_title = \"Time-based\"\n",
    "\n",
    "# Define file paths for output CSV and plot files based on the base file name\n",
    "column_output_csv = f'F:/pearson/Distance/output/{base_file_name}_distance.csv'\n",
    "column_output_plot = f'F:/pearson/Distance/plot/{base_file_name}_distance_plot.png'\n",
    "row_output_csv = f'F:/pearson/Time/output/{base_file_name}_time.csv'\n",
    "row_output_plot = f'F:/pearson/Time/plot/{base_file_name}_time_plot.png'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Pearson Velocity Coeffecient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-14ad01370ffc>:100: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr_coeff /= pair_counts  # Add 1 to avoid division by zero\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv(input_csv_path)\n",
    "# Get the unique time points\n",
    "time_points = df['Time'].unique()\n",
    "\n",
    "# Create empty lists to store the arrays\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "z_vals = []\n",
    "vx_vals = []\n",
    "vy_vals = []\n",
    "vz_vals = []\n",
    "\n",
    "# Loop through each time point and extract the arrays\n",
    "for t in time_points:\n",
    "    # Get the rows for the current time point\n",
    "    rows = df[df['Time'] == t]\n",
    "\n",
    "    # Extract the arrays\n",
    "    x = rows['Position X'].values\n",
    "    y = rows['Position Y'].values\n",
    "    z = rows['Position Z'].values\n",
    "    vx = rows['Velocity X'].values\n",
    "    vy = rows['Velocity Y'].values\n",
    "    vz = rows['Velocity Z'].values\n",
    "\n",
    "    # Append the arrays to the lists\n",
    "    x_vals.append(x)\n",
    "    y_vals.append(y)\n",
    "    z_vals.append(z)\n",
    "    vx_vals.append(vx)\n",
    "    vy_vals.append(vy)\n",
    "    vz_vals.append(vz)\n",
    "\n",
    "# Define the width or size of each distance bin\n",
    "dr = 2  # Modify this value according to your requirements\n",
    "\n",
    "# Create an empty dictionary to store the correlation coefficient\n",
    "C = {}\n",
    "\n",
    "# Loop through each time point\n",
    "for t in range(len(time_points)):\n",
    "    # Get the arrays for the current time point\n",
    "    current_x = x_vals[t]\n",
    "    current_y = y_vals[t]\n",
    "    current_z = z_vals[t]\n",
    "    current_vx = vx_vals[t]\n",
    "    current_vy = vy_vals[t]\n",
    "    current_vz = vz_vals[t]\n",
    "\n",
    "    # Calculate the number of particles\n",
    "    num_particles = len(current_x)\n",
    "\n",
    "    # Calculate the maximum distance between particles at the current time point\n",
    "    max_distance = 0\n",
    "\n",
    "    # Loop through each particle pair\n",
    "    for i in range(num_particles - 1):\n",
    "        for j in range(i + 1, num_particles):\n",
    "            # Calculate the distance between the particles\n",
    "            distance = np.sqrt((current_x[i] - current_x[j]) ** 2 +\n",
    "                               (current_y[i] - current_y[j]) ** 2 +\n",
    "                               (current_z[i] - current_z[j]) ** 2)\n",
    "\n",
    "            max_distance = max(max_distance, distance)\n",
    "\n",
    "    # Calculate the total number of distance bins\n",
    "    num_bins = int(np.ceil(max_distance / dr))  # Calculate based on 0.1 micron interval\n",
    "\n",
    "    # Create an empty array to store the correlation coefficient for each distance bin\n",
    "    corr_coeff = np.zeros(num_bins)\n",
    "\n",
    "    # Create an empty array to store the count of particle pairs in each distance bin\n",
    "    pair_counts = np.zeros(num_bins)\n",
    "\n",
    "    # Loop through each particle pair\n",
    "    for i in range(num_particles - 1):\n",
    "        for j in range(i + 1, num_particles):\n",
    "            # Calculate the distance between the particles\n",
    "            distance = np.sqrt((current_x[i] - current_x[j]) ** 2 +\n",
    "                               (current_y[i] - current_y[j]) ** 2 +\n",
    "                               (current_z[i] - current_z[j]) ** 2)\n",
    "\n",
    "            # Find the bin index for the distance (use floor to round down)\n",
    "            bin_index = int(distance / dr)  # Use 0.1 micron interval\n",
    "\n",
    "            # Ensure that bin_index is within the range of pair_counts\n",
    "            if bin_index < num_bins:\n",
    "                # Increment the count of particle pairs in the corresponding bin\n",
    "                pair_counts[bin_index] += 1\n",
    "\n",
    "\n",
    "                # Calculate the correlation coefficient (Pearson)\"\"\"\n",
    "                correlation = (np.corrcoef([current_vx[i], current_vy[i], current_vz[i]],[current_vx[j], current_vy[j], current_vz[j]])[0, 1])\n",
    "\n",
    "                # Increment the corresponding bin with the correlation coefficient\n",
    "                corr_coeff[bin_index] += correlation\n",
    "\n",
    "    # Normalize the correlation coefficient by the number of particle pairs in each bin\n",
    "    corr_coeff /= pair_counts  # Add 1 to avoid division by zero\n",
    "\n",
    "    # Store the correlation coefficient array for the current time point\n",
    "    C[t] = corr_coeff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Velocity correlation data has been exported to F:/pearson/23_03_23_E6_PVDRNz_pearson2.csv.\n"
     ]
    }
   ],
   "source": [
    "# Find the length of the longest correlation array in C\n",
    "max_corr_length = max(len(correlation) for correlation in C.values())\n",
    "\n",
    "# Define the header\n",
    "last_distance_bin_index = max_corr_length  # Index of the last \"Distance Bin\"\n",
    "header = ['Time Point'] + [f'Distance Bin {i}' for i in range(last_distance_bin_index)]\n",
    "\n",
    "# Export the velocity correlation data as CSV\n",
    "with open(pearson_csv, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    writer.writerow(header)\n",
    "    \n",
    "    # Write the data rows\n",
    "    for t, correlation in C.items():\n",
    "        data_row = [t] + list(correlation[:last_distance_bin_index])\n",
    "        writer.writerow(data_row)\n",
    "\n",
    "print(f\"Velocity correlation data has been exported to {pearson_csv}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
